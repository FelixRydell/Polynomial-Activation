# Polynomial-Activation
Training Coefficients of Polynomial Activation Functions

In this notebook we use polynomial activation functions to train a basic neural network on the MNIST database, with the addition that we also train the coefficients of the activation functions. 

The result is that for low enough degrees, the activation polynomial tends to a polynomial that looks locally like ReLU at the origin.
